{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to make 4 classifications based on balance due and the portion of the penality paid\n",
    "def make_classification(penality, paid, due):\n",
    "    if due == 0:\n",
    "        if penality > paid:\n",
    "            classification = 0\n",
    "            desc = 'NO BALANCE - PARITALLY PAID'\n",
    "        else:\n",
    "            classification = 1\n",
    "            desc = 'NO BALANCE - PAID IN FULL'\n",
    "    else:\n",
    "        if paid == 0:\n",
    "            classification = 2\n",
    "            desc = 'BALANCE DUE - UNPAID'\n",
    "        else:\n",
    "            classification = 3\n",
    "            desc = 'BALANCE DUE - PARITALLY PAID'\n",
    "    return classification, desc\n",
    "\n",
    "# convert values to float\n",
    "def make_float(expected_float):\n",
    "    try:\n",
    "        if type(expected_float) == str:\n",
    "            expected_float = expected_float.replace('+', '').replace(',', '')\n",
    "        return float(expected_float)\n",
    "    except:\n",
    "        # print expected_float\n",
    "        return np.nan\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trump owned buildings identified from:\n",
    "# https://www.bisnow.com/new-york/news/economy/how-big-is-trumps-nyc-empire-63995?single-page\n",
    "\n",
    "# BIN NUMBER\n",
    "_40_WALL_ST = '1001018' # TRUMP_BUILDING\n",
    "_1290_AVENUE_OF_THE_AMERICAS = '1034510' # _1290_AVENUE_OF_THE_AMERICAS 30% Stake in Vornado owned building\n",
    "_1_CENTRAL_PARK_WEST = '1027191' # TRUMP_INTERNATIONAL_HOTEL_AND_TOWER\n",
    "_725_5TH_AVE = '1035794' # TRUMP_TOWER\n",
    "_246_SPRING_ST = '1088431' # TRUMP_SOHO\n",
    "_502_PARK_AVE = '1040756' # TRUMP_PARK_AVE\n",
    "_327_E_47TH_ST = '1038908' # TRUMP_WORLD_TOWER\n",
    "_200_E_69TH_ST = '1043902' # TRUMP_PALACE\n",
    "_106_CENTRAL_PARK_S = '1069595' # TRUMP_PARC\n",
    "_610_PARK_AVE = '1041086' # _610_PARK_AVE\n",
    "\n",
    "TRUMP_BUILDINGS = [_106_CENTRAL_PARK_S, _1290_AVENUE_OF_THE_AMERICAS, \n",
    "                   _1_CENTRAL_PARK_WEST, _200_E_69TH_ST, _246_SPRING_ST, \n",
    "                   _327_E_47TH_ST, _40_WALL_ST, _502_PARK_AVE,\n",
    "                   _610_PARK_AVE, _725_5TH_AVE]\n",
    "# Wollman Rink - Central Park (Not a building)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DOB ECB BUILDING VIOLATION DATA\n",
    "DOB_ECB = 'data/20170322_DOB_ECB_Violations.csv'\n",
    "# CENSUS ACS 2015 5-YEAR ESTIMATES (CENSUS TRACT LEVEL)\n",
    "ACS_5YR_RACE = 'data/CENSUS_TRACT_RACE_INCOME/ACS_15_5YR_DP05_with_ann.csv'\n",
    "ACS_5YR_INCOME = 'data/CENSUS_TRACT_RACE_INCOME/ACS_15_5YR_S1901_with_ann.csv'\n",
    "# PLUTO SHAPE FILES - BBL DATA FOR ALL NYC\n",
    "PLUTO_BX = 'data/PLUTO/Bronx/BXMapPLUTO.shp'\n",
    "PLUTO_BK = 'data/PLUTO/Brooklyn/BKMapPLUTO.shp'\n",
    "PLUTO_QN = 'data/PLUTO/Queens/QNMapPLUTO.shp'\n",
    "PLUTO_MN = 'data/PLUTO/Manhattan/MNMapPLUTO.shp'\n",
    "PLUTO_SI = 'data/PLUTO/Staten_Island/SIMapPLUTO.shp'\n",
    "# CENSUS TRACT SHAPE FILES\n",
    "CENSUS_TRACT_SHAPEFILE = 'data/CENSUS_TRACT_SHAPEFILE/cb_2015_36_tract_500k.shp'\n",
    "# FILE NAME OF PROCESSED PLUTO DATA - IMPROVES PERFORMANCE OF NOTEBOOK AFTER INITIAL RUN\n",
    "MASTER_PLUTO_PICKLE = 'processed_data/master_pluto.pickle'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nate/anaconda3/envs/py27/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "DF_DOB_ECB = pd.read_csv(DOB_ECB, usecols=['BIN', 'ISSUE_DATE', 'SEVERITY', \n",
    "                                           'PENALITY_IMPOSED', 'AMOUNT_PAID', \n",
    "                                           'BALANCE_DUE', 'ECB_VIOLATION_STATUS', \n",
    "                                           'BORO', 'BLOCK', 'LOT', 'VIOLATION_DESCRIPTION',\n",
    "                                           'INFRACTION_CODE1'],\n",
    "                         dtype={'BIN': str, 'PENALITY_IMPOSED': float,\n",
    "                                'AMOUNT_PAID': float, 'BALANCE_DUE': float}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"TRUMP PROPERTIES\" WITH FINES 181\n",
      "PENALITY IMPOSED 183425.0\n",
      "AMOUNT_PAID 177357.27\n",
      "OUTSTANDING BALANCE 765.34\n"
     ]
    }
   ],
   "source": [
    "# Only 181 FINES associated with trump buildings\n",
    "\n",
    "print '\"TRUMP PROPERTIES\" WITH FINES', len(DF_DOB_ECB[(DF_DOB_ECB['PENALITY_IMPOSED'] > 0) & (DF_DOB_ECB['BIN'].isin(TRUMP_BUILDINGS))])\n",
    "print 'PENALITY IMPOSED', DF_DOB_ECB[(DF_DOB_ECB['PENALITY_IMPOSED'] > 0) & (DF_DOB_ECB['BIN'].isin(TRUMP_BUILDINGS))]['PENALITY_IMPOSED'].sum()\n",
    "print 'AMOUNT_PAID', DF_DOB_ECB[(DF_DOB_ECB['PENALITY_IMPOSED'] > 0) & (DF_DOB_ECB['BIN'].isin(TRUMP_BUILDINGS))]['AMOUNT_PAID'].sum()\n",
    "print 'OUTSTANDING BALANCE', DF_DOB_ECB[(DF_DOB_ECB['PENALITY_IMPOSED'] > 0) & (DF_DOB_ECB['BIN'].isin(TRUMP_BUILDINGS))]['BALANCE_DUE'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perhaps fines associated with trump owned buildings may not hold enough data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748325710.25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VIOLATIONS WITH A BALANCE DUE\n",
    "DF_DOB_ECB[DF_DOB_ECB['BALANCE_DUE'] > 0]['BALANCE_DUE'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1669745657.52"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TOTAL PENALITIES VALUE\n",
    "DF_DOB_ECB['PENALITY_IMPOSED'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616422508.6099999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FINES PAID\n",
    "DF_DOB_ECB['AMOUNT_PAID'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF_DOB_ECB_FINES = DF_DOB_ECB[DF_DOB_ECB['PENALITY_IMPOSED'] > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF_DOB_ECB_FINES['CLASSIFICATION'], DF_DOB_ECB_FINES['CLASS_DESC'] = np.vectorize(make_classification)(DF_DOB_ECB_FINES['PENALITY_IMPOSED'],\n",
    "                                                                                                       DF_DOB_ECB_FINES['AMOUNT_PAID'],\n",
    "                                                                                                       DF_DOB_ECB_FINES['BALANCE_DUE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ECB_VIOLATION_STATUS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLASS_DESC</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BALANCE DUE - PARITALLY PAID</th>\n",
       "      <td>31699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BALANCE DUE - UNPAID</th>\n",
       "      <td>104709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO BALANCE - PAID IN FULL</th>\n",
       "      <td>479941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO BALANCE - PARITALLY PAID</th>\n",
       "      <td>136943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ECB_VIOLATION_STATUS\n",
       "CLASS_DESC                                        \n",
       "BALANCE DUE - PARITALLY PAID                 31699\n",
       "BALANCE DUE - UNPAID                        104709\n",
       "NO BALANCE - PAID IN FULL                   479941\n",
       "NO BALANCE - PARITALLY PAID                 136943"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Breakdown of different classes\n",
    "DF_DOB_ECB_FINES[['CLASS_DESC', 'ECB_VIOLATION_STATUS']].groupby('CLASS_DESC').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# race data\n",
    "ACS_5YR_RACE_DF = pd.read_csv(ACS_5YR_RACE,skiprows=[1], usecols=['GEO.id2', 'HC01_VC03', 'HC01_VC49', 'HC01_VC50', 'HC01_VC51','HC01_VC56', 'HC01_VC64', 'HC01_VC69', 'HC01_VC23'])\n",
    "\n",
    "# rename columns\n",
    "ACS_5YR_RACE_DF.rename(columns={'HC01_VC03': 'TOTAL_POPULATION', 'HC01_VC49': 'WHITE',\n",
    "                        'HC01_VC50': 'BLACK_AFRICAN_AMERICAN', 'HC01_VC51': 'AMERICAN_INDIAN_AND_ALASKA_NATIVE',\n",
    "                        'HC01_VC56': 'ASIAN', 'HC01_VC64': 'NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER',\n",
    "                        'HC01_VC69': 'SOME_OTHER_RACE', 'HC01_VC23': 'MEDIAN_AGE', 'GEO.id2': 'GEOID'}, inplace=True)\n",
    "\n",
    "for i in ACS_5YR_RACE_DF.columns[ACS_5YR_RACE_DF.columns!='GEOID']:\n",
    "    ACS_5YR_RACE_DF[i] = ACS_5YR_RACE_DF[i].apply(lambda x: make_float(x))\n",
    "\n",
    "ACS_5YR_RACE_DF['GEOID'] = ACS_5YR_RACE_DF['GEOID'].astype(str)\n",
    "\n",
    "# income data\n",
    "ACS_5YR_INCOME_DF = pd.read_csv(ACS_5YR_INCOME,skiprows=[1],usecols=['GEO.id2', 'HC01_EST_VC01', 'HC01_EST_VC15'])\n",
    "\n",
    "# rename columns\n",
    "ACS_5YR_INCOME_DF.rename(columns={'HC01_EST_VC01': 'TOTAL_HOUSEHOLDS', \n",
    "                       'HC01_EST_VC15': 'MEAN_INCOME', 'GEO.id2': 'GEOID'}, inplace=True)\n",
    "\n",
    "#convert values to float\n",
    "for i in ACS_5YR_INCOME_DF.columns[ACS_5YR_INCOME_DF.columns!='GEOID']:\n",
    "    ACS_5YR_INCOME_DF[i] = ACS_5YR_INCOME_DF[i].apply(lambda x: make_float(x))\n",
    "\n",
    "ACS_5YR_INCOME_DF['GEOID'] = ACS_5YR_RACE_DF['GEOID'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_filter_pluto():\n",
    "    \n",
    "    # import PLUTO for 5 boros\n",
    "    BK = gp.read_file(PLUTO_BK)\n",
    "    BX = gp.read_file(PLUTO_BX)\n",
    "    MN = gp.read_file(PLUTO_MN)\n",
    "    QN = gp.read_file(PLUTO_QN)\n",
    "    SI = gp.read_file(PLUTO_SI)\n",
    "    \n",
    "    # merge 5 boro PLUTO datasets \n",
    "    pluto_agg = BK.append(BX)\n",
    "    pluto_agg = pluto_agg.append(MN)\n",
    "    pluto_agg = pluto_agg.append(QN)\n",
    "    pluto_agg = pluto_agg.append(SI)\n",
    "    \n",
    "    pluto_select = pluto_agg[['BBL','YearBuilt','Tract2010','UnitsRes',\n",
    "    'BldgClass','LandUse','BldgArea',\n",
    "    'ComArea',\n",
    "    'ResArea',\n",
    "    'UnitsTotal',\n",
    "    'AssessTot',\n",
    "    'BuiltFAR','LotArea','OwnerType']]\n",
    "    with open(MASTER_PLUTO_PICKLE, 'wb') as handle:\n",
    "        pickle.dump(pluto_select, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### CLEANING PLUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists. Loading pickle...\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(MASTER_PLUTO_PICKLE):\n",
    "    print \"File exists. Loading pickle...\"\n",
    "    # load pickle of PLUTO data\n",
    "    with open(MASTER_PLUTO_PICKLE, 'rb') as handle:\n",
    "        master_pluto = pickle.load(handle)\n",
    "    print \"File loaded!\"\n",
    "    \n",
    "else:\n",
    "    print \"File does not yet exist. Importing and filtering PLUTO. This could take several minutes...\"\n",
    "    # first time only, import, filter, and save processed PLUTO as a pickle for future use\n",
    "    import_filter_pluto()\n",
    "    \n",
    "    # load pickle of PLUTO data\n",
    "    with open(MASTER_PLUTO_PICKLE, 'rb') as handle:\n",
    "        master_pluto = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boro_to_ct = {'1':'36061','2':'36005','3':'36047','4':'36081','5':'36085'}\n",
    "\n",
    "master_pluto['ST_CT_FIPS'] = master_pluto['BBL'].apply(lambda x: boro_to_ct[str(x)[0]])\n",
    "master_pluto['Tract2010'] = master_pluto['Tract2010'].apply(lambda x: x + '00' if len(x) == 4 else x)\n",
    "master_pluto['GEOID'] = master_pluto['ST_CT_FIPS'] + master_pluto['Tract2010']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_pluto['BBL'] = master_pluto['BBL'].astype(int)\n",
    "master_pluto['BBL'] = master_pluto['BBL'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3000060010'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_pluto.reset_index()['BBL'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF_DOB_ECB_FINES.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF_DOB_ECB_FINES['BORO'] = DF_DOB_ECB_FINES['BORO'].astype(str)\n",
    "DF_DOB_ECB_FINES['BORO'] = DF_DOB_ECB_FINES['BORO'].apply(lambda x: x.split('.')[0])\n",
    "DF_DOB_ECB_FINES['BLOCK'] = DF_DOB_ECB_FINES['BLOCK'].astype(str)\n",
    "DF_DOB_ECB_FINES['BLOCK'] = DF_DOB_ECB_FINES['BLOCK'].apply(lambda x: x.split('.')[0])\n",
    "DF_DOB_ECB_FINES['BLOCK'] = DF_DOB_ECB_FINES['BLOCK'].apply(lambda x: x if len(x) == 5 else ((5-len(x))*'0') + x)\n",
    "DF_DOB_ECB_FINES['LOT'] = DF_DOB_ECB_FINES['LOT'].astype(str)\n",
    "DF_DOB_ECB_FINES['LOT'] = DF_DOB_ECB_FINES['LOT'].apply(lambda x: x.split('.')[0])\n",
    "DF_DOB_ECB_FINES['LOT'] = DF_DOB_ECB_FINES['LOT'].apply(lambda x: x if len(x) == 5 else ((4-len(x))*'0') + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF_DOB_ECB_FINES['BBL'] = DF_DOB_ECB_FINES['BORO'] + DF_DOB_ECB_FINES['BLOCK'] + DF_DOB_ECB_FINES['LOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MERGE_DF = DF_DOB_ECB_FINES.merge(master_pluto, how='left', on='BBL').merge(ACS_5YR_INCOME_DF, how='left', on='GEOID').merge(ACS_5YR_RACE_DF, how='left', on='GEOID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_select = ['CLASSIFICATION', 'CLASS_DESC', 'BIN', 'BBL', 'GEOID', 'PENALITY_IMPOSED', \n",
    "              'YearBuilt', 'UnitsRes', 'BldgArea', 'ComArea',\n",
    "              'ResArea', 'UnitsTotal', 'AssessTot', 'LotArea',\n",
    "              'TOTAL_HOUSEHOLDS', 'MEAN_INCOME', 'TOTAL_POPULATION', 'MEDIAN_AGE', 'WHITE',\n",
    "              'BLACK_AFRICAN_AMERICAN', 'AMERICAN_INDIAN_AND_ALASKA_NATIVE', 'ASIAN',\n",
    "              'NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER', 'SOME_OTHER_RACE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MASTER_DF = MERGE_DF[col_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nate/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/Nate/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Nate/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/Nate/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Nate/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Nate/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Nate/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Nate/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Nate/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Nate/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Nate/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "MASTER_DF['YearBuilt'] = 2017. - MASTER_DF['YearBuilt']\n",
    "MASTER_DF['UnitsNonRes'] = (MASTER_DF['UnitsTotal'] - MASTER_DF['UnitsRes']) / (MASTER_DF['UnitsTotal'] * 1.0) \n",
    "MASTER_DF['UnitsRes'] = MASTER_DF['UnitsRes'] / (MASTER_DF['UnitsTotal'] * 1.0) \n",
    "MASTER_DF['HOUSEHOLD_SIZE'] = MASTER_DF['TOTAL_POPULATION'] / (MASTER_DF['TOTAL_HOUSEHOLDS'] * 1.0)\n",
    "MASTER_DF['WHITE'] = MASTER_DF['WHITE'] / (MASTER_DF['TOTAL_POPULATION'] * 1.0)\n",
    "MASTER_DF['BLACK_AFRICAN_AMERICAN'] = MASTER_DF['BLACK_AFRICAN_AMERICAN'] / (MASTER_DF['TOTAL_POPULATION'] * 1.0)\n",
    "MASTER_DF['AMERICAN_INDIAN_AND_ALASKA_NATIVE'] = MASTER_DF['AMERICAN_INDIAN_AND_ALASKA_NATIVE'] / (MASTER_DF['TOTAL_POPULATION'] * 1.0)\n",
    "MASTER_DF['ASIAN'] = MASTER_DF['ASIAN'] / (MASTER_DF['TOTAL_POPULATION'] * 1.0)\n",
    "MASTER_DF['NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER'] = MASTER_DF['NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER'] / (MASTER_DF['TOTAL_POPULATION'] * 1.0)\n",
    "MASTER_DF['SOME_OTHER_RACE'] = MASTER_DF['SOME_OTHER_RACE'] / (MASTER_DF['TOTAL_POPULATION'] * 1.0)\n",
    "MASTER_DF['MORE_THAN_ONE_RACE'] = 1.0 - (MASTER_DF['WHITE'] + MASTER_DF['BLACK_AFRICAN_AMERICAN'] +\n",
    "                                         MASTER_DF['AMERICAN_INDIAN_AND_ALASKA_NATIVE'] + MASTER_DF['ASIAN'] +\n",
    "                                         MASTER_DF['NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER'] + MASTER_DF['SOME_OTHER_RACE'])\n",
    "                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nate/anaconda3/envs/py27/lib/python2.7/site-packages/pandas/core/frame.py:2834: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  **kwargs)\n"
     ]
    }
   ],
   "source": [
    "MASTER_DF.rename(columns={'YearBuilt': 'YEARS_OLD'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CTS = gp.GeoDataFrame.from_file(CENSUS_TRACT_SHAPEFILE)\n",
    "# SQ METERS TO SQ MILES\n",
    "CTS['LAND_SQ_MI'] = CTS['ALAND'] / 2589988.1\n",
    "CTS['GEOID'] = CTS['GEOID'].astype(str)\n",
    "CTS_SELECT = CTS[['GEOID', 'LAND_SQ_MI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MASTER_DF = MASTER_DF.merge(CTS_SELECT, how='left', on='GEOID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MASTER_DF['POPULATION_DENSITY'] = MASTER_DF['TOTAL_POPULATION'] / MASTER_DF['LAND_SQ_MI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MASTER_DF = MASTER_DF[['CLASSIFICATION', 'CLASS_DESC', 'BIN', 'BBL', 'GEOID', \n",
    "                       'PENALITY_IMPOSED', 'YEARS_OLD', 'UnitsRes', 'BldgArea', \n",
    "                       'AssessTot', 'MEAN_INCOME', 'MEDIAN_AGE', 'WHITE', \n",
    "                       'BLACK_AFRICAN_AMERICAN', 'AMERICAN_INDIAN_AND_ALASKA_NATIVE', \n",
    "                       'ASIAN', 'NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER',\n",
    "                       'SOME_OTHER_RACE', 'UnitsNonRes', 'HOUSEHOLD_SIZE', \n",
    "                       'MORE_THAN_ONE_RACE', 'POPULATION_DENSITY']]\n",
    "\n",
    "MASTER_DF.rename(columns={'UnitsRes': 'PERC_RES', 'BldgArea': 'BLDG_AREA',\n",
    "                          'AssessTot': 'BLDG_ASSESSMENT', 'MEDIAN_AGE': 'MEDIAN_PERSON_AGE',\n",
    "                          'UnitsNonRes': 'PERC_NON_RES'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MASTER_DF.to_csv('processed_data/FINAL_DATA.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
