{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nate/anaconda3/envs/py27/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use project clean data - OATH Violations\n",
    "\n",
    "df = pd.read_csv('processed_data/2016_FINAL_DATA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[~(df['GEOID'].isnull()) & ~(df['MEDIAN_PERSON_AGE'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['YEARS_OLD'] = df['YEARS_OLD'].apply(lambda x: 0 if x == 2017. else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)\n",
    "df.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Determine X and Y and test/train values\n",
    "df_y = df.ix[:,0]\n",
    "df_x = df.ix[:, 5:27]\n",
    "X = df_x.as_matrix()\n",
    "Y = df_y.as_matrix()\n",
    "\n",
    "# --------------------\n",
    "# K-fold CV\n",
    "# --------------------\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.7, random_state=3)\n",
    "#ts = Y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "#X_2d = scaler.fit_transform(X_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decision Tree (CART) Function\n",
    "\n",
    "\n",
    "def DT(maxdepth, ts):\n",
    "    # Train\n",
    "    dtc = DecisionTreeClassifier(max_depth = maxdepth)\n",
    "    dtc.fit(X_train, Y_train)\n",
    "\n",
    "    # Predicting\n",
    "    dtc_pred = dtc.predict(X_test)\n",
    "\n",
    "    # Finding mispredicted samples\n",
    "    dtc_verror = np.asarray([int(dtc_pred[i] != Y_test[i]) for i in range(0,ts)])\n",
    "    dtc_error = np.sum(dtc_verror)\n",
    "    dtc_ccidx = np.where(dtc_verror == 0)\n",
    "    dtc_mcidx = np.where(dtc_verror == 1)\n",
    "\n",
    "    perrordtc = float(dtc_error)/ts\n",
    "    return perrordtc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decision Tree (CART ) with Bagging/Boosting\n",
    "def bagb(maxdepth, nestimators, ts):\n",
    "    #Train\n",
    "    bagb = BaggingClassifier(DecisionTreeClassifier(max_depth=maxdepth), n_estimators=nestimators)\n",
    "    bagb.fit(X_train,Y_train)\n",
    "\n",
    "    # Predicting\n",
    "    bagb_pred = bagb.predict(X_test)\n",
    "\n",
    "    # Finding mispredicted samples\n",
    "    bagb_verror = np.asarray([int(bagb_pred[i] != Y_test[i]) for i in range(0,ts)])\n",
    "    bagb_error = np.sum(bagb_verror)\n",
    "    bagb_ccidx = np.where(bagb_verror == 0)\n",
    "    bagb_mcidx = np.where(bagb_verror == 1)\n",
    "\n",
    "    perrordtb = float(bagb_error)/ts\n",
    "    return perrordtb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM Function (choose optimal gamma first)\n",
    "\n",
    "def gammachoice(X_train, Y_train, X_test, Y_test, ts, step):  \n",
    "    l=[]\n",
    "    for g in np.logspace(-2, 5, step):\n",
    "#     for g in range(1,250, step):\n",
    "\n",
    "        svm_rbf = svm.SVC(kernel='rbf', gamma=float(g))\n",
    "        svm_rbf.fit(X_train,Y_train)\n",
    "        ypred_svm_rbf = svm_rbf.predict(X_test)\n",
    "        e_svm_rbf = float(np.sum((ypred_svm_rbf[i] != Y_test[i]) for i in range(0,ts)))\n",
    "        l.append((e_svm_rbf/ts))\n",
    "    plt.plot(range(0,250, step), l)\n",
    "    plt.xlabel('gamma')\n",
    "    plt.ylabel('classification percent error')\n",
    "    minindex = l.index(min(l)) + 1\n",
    "    #tx = plt.xticks(range(0,250, step))\n",
    "    print \"optimal gamma is:\", step*minindex\n",
    "    return step*minindex\n",
    "\n",
    "def svmrbf(X_train, Y_train, X_test, Y_test, g, ts): \n",
    "    svm_rbf = svm.SVC(kernel='rbf', gamma=g)\n",
    "    svm_rbf.fit(X_train,Y_train)\n",
    "    \n",
    "    ypred_svm_rbf = svm_rbf.predict(X_test)\n",
    "    \n",
    "    e_svm_rbf = np.sum((ypred_svm_rbf[i] != Y_test[i]) for i in range(0,ts))\n",
    "    perrorsvmrbf = float(e_svm_rbf)/ts\n",
    "    return perrorsvmrbf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059948425031894091"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-2, 5, 10)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest (No Boosting Function)\n",
    "\n",
    "def RFreg(maxdepth, nestimators):\n",
    "    #Train\n",
    "    rdf = RandomForestClassifier(max_depth=maxdepth, n_estimators=nestimators, bootstrap = True)\n",
    "    rdf.fit(X_train,Y_train)\n",
    "\n",
    "    # Predicting\n",
    "    rdf_pred = rdf.predict(X_test)\n",
    "\n",
    "    # Finding mispredicted samples\n",
    "    rdf_verror = np.asarray([int(rdf_pred[i] != Y_test[i]) for i in range(0,ts)])\n",
    "    rdf_error = np.sum(rdf_verror)\n",
    "    rdf_ccidx = np.where(rdf_verror == 0)\n",
    "    rdf_mcidx = np.where(rdf_verror == 1)\n",
    "\n",
    "    perrorrf = float(rdf_error)/ts\n",
    "    return perrorrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest (Boosting Function)\n",
    "\n",
    "def RFboost(maxdepth, nestimators):\n",
    "    #Train\n",
    "    rdfb = AdaBoostClassifier(RandomForestClassifier(max_depth=maxdepth, n_estimators=nestimators, bootstrap = True))\n",
    "    rdfb.fit(X_train,Y_train)\n",
    "\n",
    "    # Predicting\n",
    "    rdf_pred = rdfb.predict(X_test)\n",
    "\n",
    "    # Finding mispredicted samples\n",
    "    rdf_verror = np.asarray([int(rdf_pred[i] != Y_test[i]) for i in range(0,ts)])\n",
    "    rdf_error = np.sum(rdf_verror)\n",
    "    rdf_ccidx = np.where(rdf_verror == 0)\n",
    "    rdf_mcidx = np.where(rdf_verror == 1)\n",
    "\n",
    "    perrorrfb = float(rdf_error)/ts\n",
    "    return perrorrfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svml(X_train, Y_train, X_test, Y_test, ts):  \n",
    "    svm_linear = svm.SVC(kernel='linear')\n",
    "    svm_linear.fit(X_train,Y_train)\n",
    "\n",
    "    ypred_svm_linear = svm_linear.predict(X_test)\n",
    "\n",
    "    e_svm_linear = np.sum((ypred_svm_linear[i] != Y_test[i]) for i in range(0,ts))\n",
    "    pererrorsvml = float(e_svm_linear)/ts\n",
    "    return perrorsvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For Loop to determine the best parameters - training size, maxdepth and nestimators\n",
    "\n",
    "\n",
    "splits = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "maxdepthoption = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "nestimatoroptions = [5, 10, 15, 20, 25, 30, 35, 40]\n",
    "bestDTerror = 1\n",
    "bestDTsplit = 0\n",
    "bestDTdepth = 0\n",
    "bestbagerror = 1\n",
    "bestbagsplit = 0\n",
    "bestbagdepth = 0\n",
    "bestbagestimator = 0\n",
    "bestRFerror = 1\n",
    "bestRFsplit = 0\n",
    "bestRFdepth = 0\n",
    "bestRFestimator = 0\n",
    "bestRFBerror = 1\n",
    "bestRFBsplit = 0\n",
    "bestRFBdepth = 0\n",
    "bestRFBestimator = 0\n",
    "bestSVMerror = 1\n",
    "bestSVMsplit = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent of data in the training set is: 10.0\n",
      "best DT error is 0.330386213091\n",
      "best BAGDT error is 0.330386213091\n",
      "best RF error is 0.387223532053\n",
      "best Boosted RF error is 0.363786909173\n",
      "best DT error is 0.329431907488\n",
      "best BAGDT error is 0.323369260132\n",
      "best RF error is 0.337936454474\n",
      "best Boosted RF error is 0.343634220276\n",
      "best BAGDT error is 0.322499157966\n",
      "best RF error is 0.326568990681\n",
      "best BAGDT error is 0.321853598293\n",
      "best BAGDT error is 0.319018749298\n",
      "best DT error is 0.327102279106\n",
      "best BAGDT error is 0.316857527787\n",
      "best RF error is 0.32654092287\n",
      "best Boosted RF error is 0.340462557539\n",
      "best BAGDT error is 0.313882339733\n",
      "best RF error is 0.30894240485\n",
      "percent of data in the training set is: 20.0\n",
      "best DT error is 0.331175597588\n",
      "best BAGDT error is 0.331175597588\n",
      "best RF error is 0.346932331302\n",
      "best Boosted RF error is 0.335564747861\n",
      "best DT error is 0.322870946351\n",
      "best BAGDT error is 0.313713726357\n",
      "best RF error is 0.31387160946\n",
      "best BAGDT error is 0.312040165461\n",
      "best RF error is 0.310019261739\n",
      "best Boosted RF error is 0.324860273454\n",
      "best BAGDT error is 0.310777100635\n",
      "best BAGDT error is 0.309640342291\n",
      "best BAGDT error is 0.30821939436\n",
      "best RF error is 0.307145789258\n",
      "best Boosted RF error is 0.317345037734\n",
      "best BAGDT error is 0.308093087878\n",
      "percent of data in the training set is: 30.0\n",
      "best DT error is 0.33102378117\n",
      "best BAGDT error is 0.33102378117\n",
      "best RF error is 0.341128071885\n",
      "best Boosted RF error is 0.324961206741\n",
      "best DT error is 0.325069466999\n",
      "best BAGDT error is 0.312980404893\n",
      "best RF error is 0.31406300747\n",
      "best BAGDT error is 0.311176067266\n",
      "best RF error is 0.313521706182\n",
      "best Boosted RF error is 0.323517736639\n",
      "best BAGDT error is 0.311139980513\n",
      "best RF error is 0.307386958248\n",
      "best Boosted RF error is 0.316372559633\n",
      "best BAGDT error is 0.308036519794\n",
      "best RF error is 0.305474360362\n",
      "best BAGDT error is 0.307350871495\n",
      "best DT error is 0.321641225506\n",
      "best BAGDT error is 0.305510447115\n",
      "best RF error is 0.30190177186\n",
      "best Boosted RF error is 0.292555302948\n",
      "best BAGDT error is 0.302623506911\n",
      "best RF error is 0.30078308253\n",
      "best Boosted RF error is 0.29215834867\n",
      "best BAGDT error is 0.302082205622\n",
      "best RF error is 0.296452672224\n",
      "best Boosted RF error is 0.290534444805\n",
      "best BAGDT error is 0.301180036808\n",
      "best DT error is 0.320811230197\n",
      "best BAGDT error is 0.298293096604\n",
      "best RF error is 0.293529645267\n",
      "best Boosted RF error is 0.281476669914\n",
      "best BAGDT error is 0.298220923099\n",
      "best RF error is 0.291797481145\n",
      "best Boosted RF error is 0.274548013424\n",
      "best BAGDT error is 0.298040489336\n",
      "percent of data in the training set is: 40.0\n",
      "best DT error is 0.330919501516\n",
      "best BAGDT error is 0.330919501516\n",
      "best RF error is 0.432721455035\n",
      "best Boosted RF error is 0.317952172449\n",
      "best DT error is 0.324730549006\n",
      "best BAGDT error is 0.312942068036\n",
      "best RF error is 0.333487706298\n",
      "best BAGDT error is 0.309826540923\n",
      "best RF error is 0.310121252947\n",
      "best Boosted RF error is 0.311721118222\n",
      "best BAGDT error is 0.307342539576\n",
      "best DT error is 0.323299090603\n",
      "best BAGDT error is 0.303763893567\n",
      "best RF error is 0.304100707309\n",
      "best BAGDT error is 0.301743011115\n",
      "best RF error is 0.297448635904\n",
      "best Boosted RF error is 0.283386662176\n",
      "best BAGDT error is 0.298711687437\n",
      "best RF error is 0.290670259347\n",
      "best Boosted RF error is 0.270503536544\n",
      "best BAGDT error is 0.297617042775\n",
      "best BAGDT error is 0.295259346581\n",
      "best DT error is 0.321783428764\n",
      "best BAGDT error is 0.293743684742\n",
      "best RF error is 0.290459750758\n",
      "best BAGDT error is 0.292943752105\n",
      "best RF error is 0.288523071741\n",
      "best Boosted RF error is 0.268061636915\n",
      "best BAGDT error is 0.290122937016\n",
      "best RF error is 0.287175816773\n",
      "best Boosted RF error is 0.258209834961\n",
      "best DT error is 0.32035197036\n",
      "best BAGDT error is 0.289701919838\n",
      "best RF error is 0.284355001684\n",
      "best BAGDT error is 0.285407544628\n",
      "best RF error is 0.280860559111\n",
      "best Boosted RF error is 0.2571151903\n",
      "best BAGDT error is 0.282713034692\n",
      "best RF error is 0.280060626474\n",
      "best Boosted RF error is 0.254883799259\n",
      "percent of data in the training set is: 50.0\n",
      "best DT error is 0.330824028697\n",
      "best BAGDT error is 0.330824028697\n",
      "best RF error is 0.338655080079\n",
      "best Boosted RF error is 0.314808265548\n",
      "best DT error is 0.322588794018\n",
      "best BAGDT error is 0.31177689082\n",
      "best RF error is 0.323599252261\n",
      "best BAGDT error is 0.308796039004\n",
      "best RF error is 0.30965492851\n",
      "best DT error is 0.319456373465\n",
      "best BAGDT error is 0.308189764058\n",
      "best RF error is 0.300762895973\n",
      "best Boosted RF error is 0.303945839438\n",
      "best BAGDT error is 0.303390087405\n",
      "best DT error is 0.313646238569\n",
      "best BAGDT error is 0.302834335371\n",
      "best RF error is 0.295003283989\n",
      "best Boosted RF error is 0.28606072854\n",
      "best BAGDT error is 0.300813418885\n",
      "best BAGDT error is 0.300762895973\n",
      "best RF error is 0.293184459152\n",
      "best Boosted RF error is 0.274541504572\n",
      "percent of data in the training set is: 60.0\n",
      "best DT error is 0.331101989264\n",
      "best BAGDT error is 0.331101989264\n",
      "best RF error is 0.34947900221\n",
      "best Boosted RF error is 0.3165772024\n",
      "best DT error is 0.32251341964\n",
      "best BAGDT error is 0.313167035049\n",
      "best RF error is 0.319797916009\n",
      "best BAGDT error is 0.311209346385\n",
      "best RF error is 0.310198926429\n",
      "best DT error is 0.312788127566\n",
      "best BAGDT error is 0.310451531418\n",
      "best BAGDT error is 0.306725607831\n",
      "best RF error is 0.3040101042\n",
      "best Boosted RF error is 0.30217871803\n",
      "best BAGDT error is 0.306157246606\n",
      "best RF error is 0.301105146827\n",
      "best Boosted RF error is 0.300726239343\n",
      "best BAGDT error is 0.303252289233\n",
      "best DT error is 0.309630565204\n",
      "best BAGDT error is 0.298137038207\n",
      "best RF error is 0.298894853173\n",
      "best BAGDT error is 0.296053047048\n",
      "best RF error is 0.288538048626\n",
      "best Boosted RF error is 0.261825071045\n",
      "best BAGDT error is 0.293526997158\n",
      "best DT error is 0.305715187875\n",
      "best BAGDT error is 0.292263972213\n",
      "best RF error is 0.28525418377\n",
      "best Boosted RF error is 0.253362803915\n",
      "best BAGDT error is 0.290495737291\n",
      "best RF error is 0.280833596464\n",
      "best Boosted RF error is 0.245089990527\n",
      "best BAGDT error is 0.289864224818\n",
      "best RF error is 0.280580991475\n",
      "best Boosted RF error is 0.240858856962\n",
      "best BAGDT error is 0.289422166088\n",
      "best DT error is 0.301989264288\n",
      "best BAGDT error is 0.287401326176\n",
      "best BAGDT error is 0.280770445216\n",
      "best RF error is 0.274013261762\n",
      "best BAGDT error is 0.280138932744\n",
      "best RF error is 0.272623934323\n",
      "best Boosted RF error is 0.22993369119\n",
      "best BAGDT error is 0.278497000316\n",
      "best RF error is 0.271108304389\n",
      "percent of data in the training set is: 70.0\n",
      "best DT error is 0.333529808016\n",
      "best BAGDT error is 0.333529808016\n",
      "best RF error is 0.364685079151\n",
      "best Boosted RF error is 0.312899966319\n",
      "best DT error is 0.325446278208\n",
      "best BAGDT error is 0.322499157966\n",
      "best RF error is 0.316099696868\n",
      "best DT error is 0.316352307174\n",
      "best BAGDT error is 0.317110138094\n",
      "best RF error is 0.312394745706\n",
      "best BAGDT error is 0.316183900303\n",
      "best RF error is 0.305826877737\n",
      "best Boosted RF error is 0.310205456383\n",
      "best BAGDT error is 0.314920848771\n",
      "best BAGDT error is 0.312731559448\n",
      "best BAGDT error is 0.312647356012\n",
      "best RF error is 0.305490063995\n",
      "best Boosted RF error is 0.307005725834\n",
      "best DT error is 0.314331424722\n",
      "best BAGDT error is 0.309784439205\n",
      "best RF error is 0.305321657124\n",
      "best BAGDT error is 0.308100370495\n",
      "best RF error is 0.304479622769\n",
      "best Boosted RF error is 0.302290333446\n",
      "best DT error is 0.311468507915\n",
      "best BAGDT error is 0.300353654429\n",
      "best RF error is 0.294375210509\n",
      "best Boosted RF error is 0.299427416639\n",
      "best BAGDT error is 0.293112158976\n",
      "best RF error is 0.29041764904\n",
      "best Boosted RF error is 0.264482990906\n",
      "best BAGDT error is 0.292270124621\n",
      "best DT error is 0.309952846076\n",
      "best BAGDT error is 0.291343886831\n",
      "best RF error is 0.279976423038\n",
      "best Boosted RF error is 0.24418996295\n",
      "best BAGDT error is 0.28949141125\n",
      "best BAGDT error is 0.287638935669\n",
      "best DT error is 0.307005725834\n",
      "best BAGDT error is 0.284607611991\n",
      "best BAGDT error is 0.284102391378\n",
      "best RF error is 0.275345234086\n",
      "best Boosted RF error is 0.242590097676\n",
      "best BAGDT error is 0.279555405861\n",
      "best BAGDT error is 0.277618726844\n",
      "best RF error is 0.272145503537\n",
      "best Boosted RF error is 0.222465476591\n",
      "percent of data in the training set is: 80.0\n",
      "best DT error is 0.334049002273\n",
      "best BAGDT error is 0.334049002273\n",
      "best RF error is 0.357539782773\n",
      "best Boosted RF error is 0.317883303865\n",
      "best DT error is 0.321166961354\n",
      "best BAGDT error is 0.319272543572\n",
      "best RF error is 0.308158625916\n",
      "best BAGDT error is 0.315610002526\n",
      "best DT error is 0.314725940894\n",
      "best BAGDT error is 0.313968173781\n",
      "best RF error is 0.305380146502\n",
      "best Boosted RF error is 0.316620358676\n",
      "best BAGDT error is 0.309042687547\n",
      "best RF error is 0.298939126042\n",
      "best Boosted RF error is 0.297928769891\n",
      "best BAGDT error is 0.308663803991\n",
      "best BAGDT error is 0.308032331397\n",
      "best DT error is 0.313841879262\n",
      "best BAGDT error is 0.303359434201\n",
      "best BAGDT error is 0.302475372569\n",
      "best RF error is 0.293255872695\n",
      "best Boosted RF error is 0.281889366002\n",
      "best DT error is 0.313589290225\n",
      "best BAGDT error is 0.295150290477\n",
      "best RF error is 0.290351098762\n",
      "best BAGDT error is 0.292119222026\n",
      "best RF error is 0.289467037131\n",
      "best Boosted RF error is 0.249557969184\n",
      "best BAGDT error is 0.288835564536\n",
      "best RF error is 0.278984592069\n",
      "best Boosted RF error is 0.235918161152\n",
      "best BAGDT error is 0.287067441273\n",
      "best DT error is 0.312200050518\n",
      "best BAGDT error is 0.284036372821\n",
      "best RF error is 0.27456428391\n",
      "best BAGDT error is 0.278226824956\n",
      "best RF error is 0.274185400354\n",
      "best Boosted RF error is 0.219878757262\n",
      "best BAGDT error is 0.277216468805\n",
      "best RF error is 0.271785804496\n",
      "best Boosted RF error is 0.218110633998\n",
      "percent of data in the training set is: 90.0\n",
      "best DT error is 0.332407173529\n",
      "best BAGDT error is 0.332407173529\n",
      "best RF error is 0.347562515787\n",
      "best Boosted RF error is 0.308411214953\n",
      "best DT error is 0.319525132609\n",
      "best DT error is 0.311442283405\n",
      "best BAGDT error is 0.31093710533\n",
      "best RF error is 0.307148269765\n",
      "best BAGDT error is 0.310431927254\n",
      "best BAGDT error is 0.309674160141\n",
      "best RF error is 0.303864612276\n",
      "best Boosted RF error is 0.300328365749\n",
      "best DT error is 0.308158625916\n",
      "best BAGDT error is 0.307148269765\n",
      "best BAGDT error is 0.304622379389\n",
      "best RF error is 0.299570598636\n",
      "best DT error is 0.306390502652\n",
      "best BAGDT error is 0.295529174034\n",
      "best BAGDT error is 0.294013639808\n",
      "best RF error is 0.292498105582\n",
      "best Boosted RF error is 0.266986612781\n",
      "best BAGDT error is 0.29376105077\n",
      "best RF error is 0.291992927507\n",
      "best Boosted RF error is 0.266228845668\n",
      "best DT error is 0.299823187674\n",
      "best BAGDT error is 0.291740338469\n",
      "best RF error is 0.288204091942\n",
      "best Boosted RF error is 0.249052791109\n",
      "best BAGDT error is 0.290982571356\n",
      "best RF error is 0.287698913867\n",
      "best Boosted RF error is 0.245263955544\n",
      "best BAGDT error is 0.286435968679\n",
      "best RF error is 0.281636776964\n",
      "best Boosted RF error is 0.239454407679\n",
      "best DT error is 0.298560242485\n",
      "best BAGDT error is 0.284920434453\n",
      "best RF error is 0.276837585249\n",
      "best Boosted RF error is 0.227330133872\n",
      "best BAGDT error is 0.283910078303\n",
      "best RF error is 0.27027027027\n",
      "best Boosted RF error is 0.219752462743\n",
      "best BAGDT error is 0.282899722152\n",
      "best BAGDT error is 0.279616064663\n",
      "best BAGDT error is 0.278100530437\n",
      "best DT error is 0.297549886335\n",
      "best BAGDT error is 0.272290982571\n",
      "best BAGDT error is 0.267491790856\n",
      "best RF error is 0.266481434706\n",
      "best Boosted RF error is 0.204597120485\n"
     ]
    }
   ],
   "source": [
    "DTES = []\n",
    "BAGES = []\n",
    "RFES = []\n",
    "RFBES = []\n",
    "for i in splits:\n",
    "    bestDTerror = 1\n",
    "    bestbagerror = 1\n",
    "    bestRFerror = 1\n",
    "    bestRFBerror = 1\n",
    "    print \"percent of data in the training set is:\", i*100\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=i, random_state=123)\n",
    "    ts = Y_test.shape[0]\n",
    "    \n",
    "\n",
    "    \n",
    "    for j in maxdepthoption:\n",
    "        DTE = DT(j, ts)\n",
    "        if DTE < bestDTerror:\n",
    "            bestDTerror = DTE\n",
    "            bestDTsplit = i\n",
    "            bestDTdepth = j\n",
    "        else:\n",
    "            continue\n",
    "        print \"best DT error is\", bestDTerror\n",
    "        \n",
    "        for k in nestimatoroptions:\n",
    "            BAGE = bagb(j, k, ts)\n",
    "            if BAGE < bestbagerror:\n",
    "                bestbagerror = BAGE\n",
    "                bestbagsplit = i\n",
    "                bestbagdepth = j\n",
    "                bestbagestimator = k\n",
    "            else:\n",
    "                continue\n",
    "            print \"best BAGDT error is\", bestbagerror\n",
    "            \n",
    "            RFE = RFreg(j, k)\n",
    "            if RFE < bestRFerror:\n",
    "                bestRFerror = RFE\n",
    "                bestRFsplit = i\n",
    "                bestRFdepth = j\n",
    "                bestRFestimator = k\n",
    "            else:\n",
    "                continue\n",
    "            print \"best RF error is\", bestRFerror\n",
    "            \n",
    "            RFBE = RFboost(j, k)\n",
    "            if RFBE < bestRFBerror:\n",
    "                bestRFBerror = RFBE\n",
    "                bestRFBsplit = i\n",
    "                bestRFBdepth = j\n",
    "                bestRFBestimator = k\n",
    "            else:\n",
    "                continue\n",
    "            print \"best Boosted RF error is\", bestRFBerror\n",
    "    DTES.append(bestDTerror)\n",
    "    BAGES.append(bestbagerror)\n",
    "    RFES.append(bestRFerror)    \n",
    "    RFBES.append(bestRFBerror)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent of data in the training set is: 10.0\n",
      "percent of data in the training set is: 20.0\n",
      "percent of data in the training set is: 30.0\n",
      "percent of data in the training set is: 40.0\n",
      "percent of data in the training set is: 50.0\n",
      "percent of data in the training set is: 60.0\n",
      "percent of data in the training set is: 70.0\n",
      "percent of data in the training set is: 80.0\n",
      "percent of data in the training set is: 90.0\n"
     ]
    }
   ],
   "source": [
    "#SVM - SVM will use its own loop because it has different parameters than the other models \n",
    "\n",
    "svmrbf = []\n",
    "SVMRBFES = []\n",
    "\n",
    "for i in splits:\n",
    "    e = []\n",
    "    print \"percent of data in the training set is:\", i*100\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=i, random_state=123)\n",
    "    ts = Y_test.shape[0]\n",
    "    \n",
    "    \n",
    "    #choose gamma\n",
    "    step = 10\n",
    "    # g = gammachoice(X_train, Y_train, X_test, Y_test, ts, step)\n",
    "    # print g\n",
    "    # plt.legend(splits, bbox_to_anchor=(1.25, 1.0))\n",
    "    \n",
    "    #run svm rbf with that split and optimal gamma and append percent error to the svmrbf array\n",
    "    for g in np.logspace(-4, 1, 10):\n",
    "        svm_rbf = svm.SVC(kernel='rbf', gamma=g)\n",
    "        svm_rbf.fit(X_train,Y_train)\n",
    "\n",
    "        ypred_svm_rbf = svm_rbf.predict(X_test)\n",
    "\n",
    "        e_svm_rbf = np.sum((ypred_svm_rbf[i] != Y_test[i]) for i in range(0,ts))\n",
    "        perbf = float(e_svm_rbf)/ts\n",
    "        e.append(perbf)\n",
    "\n",
    "    svmrbf.append(e)\n",
    "    SVMRBFES.append(min(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3271022791063209, 0.32287094635132146, 0.32081123019739455, 0.3203519703603907, 0.3136462385691911, 0.3019892642879697, 0.307005725833614, 0.3122000505178075, 0.29754988633493307]\n",
      "[0.31388233973279445, 0.3080930878777353, 0.2980404893363646, 0.2827130346918154, 0.3007628959733239, 0.27849700031575625, 0.27761872684405525, 0.27721646880525386, 0.26749179085627683]\n",
      "[0.30894240485011787, 0.30714578925763364, 0.2917974811446718, 0.2800606264735601, 0.2931844591522255, 0.2711083043890117, 0.27214550353654426, 0.27178580449608486, 0.26648143470573377]\n",
      "[0.3404625575390143, 0.3173450377340617, 0.27454801342427193, 0.2548837992590098, 0.27454150457232357, 0.22993369119040102, 0.22246547659144494, 0.21811063399848446, 0.20459712048497095]\n",
      "[0.33313685865049963, 0.3232182891786921, 0.3133051856663419, 0.3056584708656113, 0.29692315465063407, 0.2906220397852858, 0.2858706635230717, 0.2720383935337206, 0.2649659004799192]\n"
     ]
    }
   ],
   "source": [
    "# Printing out lists for access later. 10% -> 90% for each\n",
    "print DTES\n",
    "print BAGES\n",
    "print RFES\n",
    "print RFBES\n",
    "print SVMRBFES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4422364432468845, 0.39132143258111596, 0.3800943078477602, 0.3615414842258898, 0.3350454698551701, 0.33313685865049963, 0.34298866060401934, 0.37080386213090827, 0.3989839452116313, 0.4082743909284832], [0.39262370141147496, 0.38630837727746375, 0.3709305630111466, 0.33673308282547604, 0.32697590703842877, 0.3244813540054943, 0.3232182891786921, 0.33793299441093816, 0.35978401591461684, 0.3695411917016641], [0.3892317130381437, 0.37598787485114216, 0.353938869041175, 0.32856988199631915, 0.32405903792717694, 0.3192594998376096, 0.3133051856663419, 0.3193316733427159, 0.3308072606546137, 0.34120024538991733], [0.38813573593802625, 0.3736106433142472, 0.3494442573256989, 0.32607780397440217, 0.3225833614011452, 0.3172364432468845, 0.3107527787133715, 0.3056584708656113, 0.3163523071741327, 0.32582519366790164], [0.38392360935684333, 0.36917091901177185, 0.3439599858535846, 0.3248623250644167, 0.320416308796039, 0.3136462385691911, 0.30172283130399635, 0.29692315465063407, 0.30384479361390393, 0.3078361036730157], [0.3815598358067572, 0.366277233975371, 0.33779602147142407, 0.32358699084306913, 0.32011367224502685, 0.31379854752131353, 0.29750552573413325, 0.2906220397852858, 0.29175876223555414, 0.29479002210293653], [0.38068373189626137, 0.36451667228022905, 0.33496126641966995, 0.3233411923206467, 0.3193836308521388, 0.31071067699562144, 0.29757494105759513, 0.28612327382957226, 0.2871337150555743, 0.2858706635230717], [0.37976761808537507, 0.3598130841121495, 0.33493306390502653, 0.32179843394796664, 0.3223036120232382, 0.3122000505178075, 0.29312957817630714, 0.2757009345794392, 0.2744379893912604, 0.2720383935337206], [0.37105329628694117, 0.35589795402879515, 0.33114422834049, 0.3207880777974236, 0.3220510229856024, 0.3114422834049002, 0.2887092700176812, 0.26597625663046226, 0.27128062642081335, 0.2649659004799192]]\n"
     ]
    }
   ],
   "source": [
    "print svmrbf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT 0.297549886335\n",
      "BAG 0.267491790856\n",
      "RF 0.266481434706\n",
      "RFB 0.204597120485\n",
      "SVMRBF 0.26496590048\n"
     ]
    }
   ],
   "source": [
    "# lowest percent error.\n",
    "print 'DT', min(DTES)\n",
    "print 'BAG', min(BAGES)\n",
    "print 'RF', min(RFES)\n",
    "print 'RFB', min(RFBES)\n",
    "print 'SVMRBF', min(SVMRBFES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
